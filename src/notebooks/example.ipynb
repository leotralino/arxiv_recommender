{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08637af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import logging\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# do logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77b952bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'b'.join(['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ce77892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_recent_papers(categories=[\"cs.AI\"], days=1, max_results=100):\n",
    "    \"\"\"\n",
    "    Fetches papers from specific categories within a time window.\n",
    "    \"\"\"\n",
    "    # 1. Build Query (e.g., \"cat:cs.LG OR cat:cs.AI\")\n",
    "    query = \" OR \".join([f\"cat:{c}\" for c in categories])\n",
    "    \n",
    "    client = arxiv.Client(\n",
    "        page_size=100,\n",
    "        delay_seconds=3.0, # Be nice to ArXiv servers\n",
    "        num_retries=3\n",
    "    )\n",
    "    \n",
    "    search = arxiv.Search(\n",
    "        query=query,\n",
    "        max_results=max_results,\n",
    "        sort_by=arxiv.SortCriterion.SubmittedDate\n",
    "    )\n",
    "    \n",
    "    # 2. Time Window\n",
    "    threshold = datetime.datetime.now(datetime.timezone.utc) - datetime.timedelta(days=days)\n",
    "    \n",
    "    results = []\n",
    "    for result in client.results(search):\n",
    "        # ArXiv results are sorted by date, so we can break early\n",
    "        if result.published < threshold:\n",
    "            break\n",
    "            \n",
    "        results.append({\n",
    "            \"id\": result.entry_id.split('/')[-1],\n",
    "            \"title\": result.title,\n",
    "            \"authors\": [a.name for a in result.authors],\n",
    "            \"abstract\": result.summary.replace(\"\\n\", \" \"),\n",
    "            \"published\": result.published,\n",
    "            \"primary_category\": result.primary_category,\n",
    "            \"url\": result.pdf_url,\n",
    "        })\n",
    "        \n",
    "    print(f\"Fetched {len(results)} new papers since {threshold.strftime('%Y-%m-%d %H:%M')}\")\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bd015b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:arxiv:Requesting page (first: True, try: 0): https://export.arxiv.org/api/query?search_query=cat%3Acs.AI&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=100\n",
      "INFO:arxiv:Got first page: 100 of 160178 total results\n",
      "INFO:arxiv:Sleeping: 2.973840 seconds\n",
      "INFO:arxiv:Requesting page (first: False, try: 0): https://export.arxiv.org/api/query?search_query=cat%3Acs.AI&id_list=&sortBy=submittedDate&sortOrder=descending&start=100&max_results=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 193 new papers since 2026-01-29 05:00\n"
     ]
    }
   ],
   "source": [
    "df = fetch_recent_papers(max_results=1000)\n",
    "df['combined_text'] = \"Title: \" + df['title'] + \" Abstract: \" + df['abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a00ae5b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>abstract</th>\n",
       "      <th>published</th>\n",
       "      <th>primary_category</th>\n",
       "      <th>url</th>\n",
       "      <th>combined_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2601.22159v1</td>\n",
       "      <td>RedSage: A Cybersecurity Generalist LLM</td>\n",
       "      <td>[Naufal Suryanto, Muzammal Naseer, Pengfei Li,...</td>\n",
       "      <td>Cybersecurity operations demand assistant LLMs...</td>\n",
       "      <td>2026-01-29 18:59:57+00:00</td>\n",
       "      <td>cs.CR</td>\n",
       "      <td>https://arxiv.org/pdf/2601.22159v1</td>\n",
       "      <td>Title: RedSage: A Cybersecurity Generalist LLM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2601.22156v1</td>\n",
       "      <td>Hybrid Linear Attention Done Right: Efficient ...</td>\n",
       "      <td>[Yingfa Chen, Zhen Leng Thai, Zihan Zhou, Zhu ...</td>\n",
       "      <td>Hybrid Transformer architectures, which combin...</td>\n",
       "      <td>2026-01-29 18:59:53+00:00</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>https://arxiv.org/pdf/2601.22156v1</td>\n",
       "      <td>Title: Hybrid Linear Attention Done Right: Eff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2601.22154v1</td>\n",
       "      <td>Exploring Reasoning Reward Model for Agents</td>\n",
       "      <td>[Kaixuan Fan, Kaituo Feng, Manyuan Zhang, Tian...</td>\n",
       "      <td>Agentic Reinforcement Learning (Agentic RL) ha...</td>\n",
       "      <td>2026-01-29 18:59:52+00:00</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>https://arxiv.org/pdf/2601.22154v1</td>\n",
       "      <td>Title: Exploring Reasoning Reward Model for Ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2601.22149v1</td>\n",
       "      <td>DynaWeb: Model-Based Reinforcement Learning of...</td>\n",
       "      <td>[Hang Ding, Peidong Liu, Junqiao Wang, Ziwei J...</td>\n",
       "      <td>The development of autonomous web agents, powe...</td>\n",
       "      <td>2026-01-29 18:59:07+00:00</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>https://arxiv.org/pdf/2601.22149v1</td>\n",
       "      <td>Title: DynaWeb: Model-Based Reinforcement Lear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2601.22141v1</td>\n",
       "      <td>Routing the Lottery: Adaptive Subnetworks for ...</td>\n",
       "      <td>[Grzegorz Stefanski, Alberto Presta, Michal Byra]</td>\n",
       "      <td>In pruning, the Lottery Ticket Hypothesis posi...</td>\n",
       "      <td>2026-01-29 18:56:41+00:00</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>https://arxiv.org/pdf/2601.22141v1</td>\n",
       "      <td>Title: Routing the Lottery: Adaptive Subnetwor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>2601.21283v1</td>\n",
       "      <td>DUET: Distilled LLM Unlearning from an Efficie...</td>\n",
       "      <td>[Yisheng Zhong, Zhengbang Yang, Zhuangdi Zhu]</td>\n",
       "      <td>LLM unlearning is a technique to remove the im...</td>\n",
       "      <td>2026-01-29 05:32:35+00:00</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>https://arxiv.org/pdf/2601.21283v1</td>\n",
       "      <td>Title: DUET: Distilled LLM Unlearning from an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>2601.21279v1</td>\n",
       "      <td>NEXUS: Bit-Exact ANN-to-SNN Equivalence via Ne...</td>\n",
       "      <td>[Zhengzheng Tang]</td>\n",
       "      <td>Spiking Neural Networks (SNNs) promise energy-...</td>\n",
       "      <td>2026-01-29 05:23:56+00:00</td>\n",
       "      <td>cs.NE</td>\n",
       "      <td>https://arxiv.org/pdf/2601.21279v1</td>\n",
       "      <td>Title: NEXUS: Bit-Exact ANN-to-SNN Equivalence...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>2601.21278v1</td>\n",
       "      <td>GeoRC: A Benchmark for Geolocation Reasoning C...</td>\n",
       "      <td>[Mohit Talreja, Joshua Diao, Jim Thannikary Ja...</td>\n",
       "      <td>Vision Language Models (VLMs) are good at reco...</td>\n",
       "      <td>2026-01-29 05:18:40+00:00</td>\n",
       "      <td>cs.CV</td>\n",
       "      <td>https://arxiv.org/pdf/2601.21278v1</td>\n",
       "      <td>Title: GeoRC: A Benchmark for Geolocation Reas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>2601.21276v1</td>\n",
       "      <td>More Code, Less Reuse: Investigating Code Qual...</td>\n",
       "      <td>[Haoming Huang, Pongchai Jaisri, Shota Shimizu...</td>\n",
       "      <td>Large Language Model (LLM) Agents are advancin...</td>\n",
       "      <td>2026-01-29 05:13:21+00:00</td>\n",
       "      <td>cs.SE</td>\n",
       "      <td>https://arxiv.org/pdf/2601.21276v1</td>\n",
       "      <td>Title: More Code, Less Reuse: Investigating Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>2601.21269v1</td>\n",
       "      <td>Lightweight High-Fidelity Low-Bitrate Talking ...</td>\n",
       "      <td>[Jianglong Li, Jun Xu, Bingcong Lu, Zhengxue C...</td>\n",
       "      <td>The demand for immersive and interactive commu...</td>\n",
       "      <td>2026-01-29 05:03:29+00:00</td>\n",
       "      <td>cs.CV</td>\n",
       "      <td>https://arxiv.org/pdf/2601.21269v1</td>\n",
       "      <td>Title: Lightweight High-Fidelity Low-Bitrate T...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                              title  \\\n",
       "0    2601.22159v1            RedSage: A Cybersecurity Generalist LLM   \n",
       "1    2601.22156v1  Hybrid Linear Attention Done Right: Efficient ...   \n",
       "2    2601.22154v1        Exploring Reasoning Reward Model for Agents   \n",
       "3    2601.22149v1  DynaWeb: Model-Based Reinforcement Learning of...   \n",
       "4    2601.22141v1  Routing the Lottery: Adaptive Subnetworks for ...   \n",
       "..            ...                                                ...   \n",
       "188  2601.21283v1  DUET: Distilled LLM Unlearning from an Efficie...   \n",
       "189  2601.21279v1  NEXUS: Bit-Exact ANN-to-SNN Equivalence via Ne...   \n",
       "190  2601.21278v1  GeoRC: A Benchmark for Geolocation Reasoning C...   \n",
       "191  2601.21276v1  More Code, Less Reuse: Investigating Code Qual...   \n",
       "192  2601.21269v1  Lightweight High-Fidelity Low-Bitrate Talking ...   \n",
       "\n",
       "                                               authors  \\\n",
       "0    [Naufal Suryanto, Muzammal Naseer, Pengfei Li,...   \n",
       "1    [Yingfa Chen, Zhen Leng Thai, Zihan Zhou, Zhu ...   \n",
       "2    [Kaixuan Fan, Kaituo Feng, Manyuan Zhang, Tian...   \n",
       "3    [Hang Ding, Peidong Liu, Junqiao Wang, Ziwei J...   \n",
       "4    [Grzegorz Stefanski, Alberto Presta, Michal Byra]   \n",
       "..                                                 ...   \n",
       "188      [Yisheng Zhong, Zhengbang Yang, Zhuangdi Zhu]   \n",
       "189                                  [Zhengzheng Tang]   \n",
       "190  [Mohit Talreja, Joshua Diao, Jim Thannikary Ja...   \n",
       "191  [Haoming Huang, Pongchai Jaisri, Shota Shimizu...   \n",
       "192  [Jianglong Li, Jun Xu, Bingcong Lu, Zhengxue C...   \n",
       "\n",
       "                                              abstract  \\\n",
       "0    Cybersecurity operations demand assistant LLMs...   \n",
       "1    Hybrid Transformer architectures, which combin...   \n",
       "2    Agentic Reinforcement Learning (Agentic RL) ha...   \n",
       "3    The development of autonomous web agents, powe...   \n",
       "4    In pruning, the Lottery Ticket Hypothesis posi...   \n",
       "..                                                 ...   \n",
       "188  LLM unlearning is a technique to remove the im...   \n",
       "189  Spiking Neural Networks (SNNs) promise energy-...   \n",
       "190  Vision Language Models (VLMs) are good at reco...   \n",
       "191  Large Language Model (LLM) Agents are advancin...   \n",
       "192  The demand for immersive and interactive commu...   \n",
       "\n",
       "                    published primary_category  \\\n",
       "0   2026-01-29 18:59:57+00:00            cs.CR   \n",
       "1   2026-01-29 18:59:53+00:00            cs.CL   \n",
       "2   2026-01-29 18:59:52+00:00            cs.AI   \n",
       "3   2026-01-29 18:59:07+00:00            cs.CL   \n",
       "4   2026-01-29 18:56:41+00:00            cs.AI   \n",
       "..                        ...              ...   \n",
       "188 2026-01-29 05:32:35+00:00            cs.LG   \n",
       "189 2026-01-29 05:23:56+00:00            cs.NE   \n",
       "190 2026-01-29 05:18:40+00:00            cs.CV   \n",
       "191 2026-01-29 05:13:21+00:00            cs.SE   \n",
       "192 2026-01-29 05:03:29+00:00            cs.CV   \n",
       "\n",
       "                                    url  \\\n",
       "0    https://arxiv.org/pdf/2601.22159v1   \n",
       "1    https://arxiv.org/pdf/2601.22156v1   \n",
       "2    https://arxiv.org/pdf/2601.22154v1   \n",
       "3    https://arxiv.org/pdf/2601.22149v1   \n",
       "4    https://arxiv.org/pdf/2601.22141v1   \n",
       "..                                  ...   \n",
       "188  https://arxiv.org/pdf/2601.21283v1   \n",
       "189  https://arxiv.org/pdf/2601.21279v1   \n",
       "190  https://arxiv.org/pdf/2601.21278v1   \n",
       "191  https://arxiv.org/pdf/2601.21276v1   \n",
       "192  https://arxiv.org/pdf/2601.21269v1   \n",
       "\n",
       "                                         combined_text  \n",
       "0    Title: RedSage: A Cybersecurity Generalist LLM...  \n",
       "1    Title: Hybrid Linear Attention Done Right: Eff...  \n",
       "2    Title: Exploring Reasoning Reward Model for Ag...  \n",
       "3    Title: DynaWeb: Model-Based Reinforcement Lear...  \n",
       "4    Title: Routing the Lottery: Adaptive Subnetwor...  \n",
       "..                                                 ...  \n",
       "188  Title: DUET: Distilled LLM Unlearning from an ...  \n",
       "189  Title: NEXUS: Bit-Exact ANN-to-SNN Equivalence...  \n",
       "190  Title: GeoRC: A Benchmark for Geolocation Reas...  \n",
       "191  Title: More Code, Less Reuse: Investigating Co...  \n",
       "192  Title: Lightweight High-Fidelity Low-Bitrate T...  \n",
       "\n",
       "[193 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b28bc8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yang/Desktop/open_source/arxiv_recommender/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: mps\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/README.md \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/sentence_bert_config.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json \"HTTP/1.1 200 OK\"\n",
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 1961.68it/s, Materializing param=pooler.dense.weight]                             \n",
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/1_Pooling/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/1_Pooling%2Fconfig.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2 \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fb86910",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  9.53it/s]\n",
      "Batches: 100%|██████████| 7/7 [00:01<00:00,  5.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(193, 384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "my_interest_embedding = model.encode(\"I am interested in Retrieval-augmented generation (RAG).\")\n",
    "content_embedding = model.encode(df['combined_text'].tolist())\n",
    "\n",
    "print(np.shape(content_embedding))\n",
    "\n",
    "cosine_sim = np.dot(content_embedding, my_interest_embedding) / (np.linalg.norm(content_embedding, axis=1) * np.linalg.norm(my_interest_embedding))\n",
    "top_k_indices = np.argsort(-cosine_sim)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05663656",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_df = df.iloc[top_k_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "377554e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import json\n",
    "\n",
    "def get_authors(author_list):\n",
    "    \"\"\"\n",
    "    Formats the author list for LLM input, truncating if too long.\n",
    "    \"\"\"\n",
    "    # Assuming 'authors' is your list of strings\n",
    "    num_authors = len(author_list)\n",
    "\n",
    "    if num_authors <= 12:\n",
    "        # If list is small, just give them all\n",
    "        author_string = \", \".join(author_list)\n",
    "    else:\n",
    "        # Grab first 10 and last 2 (senior/corresponding positions)\n",
    "        first_part = author_list[:10]\n",
    "        last_part = author_list[-2:]\n",
    "        author_string = f\"{', '.join(first_part)} ... {', '.join(last_part)}\"\n",
    "    \n",
    "    return author_string\n",
    "\n",
    "def fine_rank_with_llm(top_papers_df, user_interest=\"RAG\"):\n",
    "    \"\"\"\n",
    "    Uses a local LLM to give a qualitative 'Quality Score' to the top candidates.\n",
    "    \"\"\"\n",
    "    top_papers_df = top_papers_df.copy()\n",
    "    top_papers_df['cleaned_authors'] = top_papers_df['authors'].apply(get_authors)\n",
    "    all_papers_json = top_papers_df[['id', 'title', 'cleaned_authors', 'abstract']].to_dict(orient='records')\n",
    "\n",
    "    print(len(all_papers_json))    \n",
    "    print(all_papers_json)\n",
    "\n",
    "    llm_ranking_prompt = f\"\"\"\n",
    "    ## Task\n",
    "\n",
    "    You are an expert AI and Physics PhD Researcher. \n",
    "    Given a list of papers with their titles, authors, and abstracts, you should help me decide which research papers to read based on my specific interest.\n",
    "    These papers are posted on arXiv today.\n",
    "    Your output should be top-5 results, stored in JSON format.\n",
    "\n",
    "    To select best papers, you should consider relevancy to my interest, novelty, and soundness of methodology. Use the author list to gauge credibility if needed.\n",
    "    \n",
    "\n",
    "    ## My Interest\n",
    "    My research interest topics: \"{user_interest}\"\n",
    "\n",
    "    \n",
    "    ## Input paper as JSON array\n",
    "    {all_papers_json}\n",
    "\n",
    "    ## Output\n",
    "\n",
    "    Provide a JSON response with:\n",
    "    - \"id\": The ArXiv ID of the paper.\n",
    "    - \"reasoning\": A one-sentence explanation of why this paper is worth reading or not.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = ollama.generate(\n",
    "        model='llama3:8b', \n",
    "        prompt=llm_ranking_prompt,\n",
    "        format='json', # Ensures we get a parsable dict back\n",
    "        options={'temperature': 0} # Keep it deterministic\n",
    "    )\n",
    "    \n",
    "    llm_output = json.loads(response['response'])\n",
    "\n",
    "    refined_results = []\n",
    "    for paper_analysis in llm_output:\n",
    "        paper_id = paper_analysis['id']\n",
    "        matching_paper = top_papers_df[top_papers_df['id'] == paper_id].iloc[0]\n",
    "        \n",
    "        refined_results.append({\n",
    "            \"id\": paper_id,\n",
    "            \"url\": matching_paper['url'],\n",
    "            \"title\": matching_paper['title'],\n",
    "            \"authors\": matching_paper['cleaned_authors'],\n",
    "            \"abstract\": matching_paper['abstract'],\n",
    "            \"reasoning\": paper_analysis.get('why', '')\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(refined_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2b0e3420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>abstract</th>\n",
       "      <th>published</th>\n",
       "      <th>primary_category</th>\n",
       "      <th>url</th>\n",
       "      <th>combined_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>2601.21340v1</td>\n",
       "      <td>EHR-RAG: Bridging Long-Horizon Structured Elec...</td>\n",
       "      <td>[Lang Cao, Qingyu Chen, Yue Guo]</td>\n",
       "      <td>Electronic Health Records (EHRs) provide rich ...</td>\n",
       "      <td>2026-01-29 07:06:34+00:00</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>https://arxiv.org/pdf/2601.21340v1</td>\n",
       "      <td>Title: EHR-RAG: Bridging Long-Horizon Structur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2601.21916v1</td>\n",
       "      <td>JADE: Bridging the Strategic-Operational Gap i...</td>\n",
       "      <td>[Yiqun Chen, Erhan Zhang, Tianyi Hu, Shijie Wa...</td>\n",
       "      <td>The evolution of Retrieval-Augmented Generatio...</td>\n",
       "      <td>2026-01-29 16:06:44+00:00</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>https://arxiv.org/pdf/2601.21916v1</td>\n",
       "      <td>Title: JADE: Bridging the Strategic-Operationa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2601.21912v1</td>\n",
       "      <td>ProRAG: Process-Supervised Reinforcement Learn...</td>\n",
       "      <td>[Zhao Wang, Ziliang Zhao, Zhicheng Dou]</td>\n",
       "      <td>Reinforcement learning (RL) has become a promi...</td>\n",
       "      <td>2026-01-29 16:04:59+00:00</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>https://arxiv.org/pdf/2601.21912v1</td>\n",
       "      <td>Title: ProRAG: Process-Supervised Reinforcemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2601.22025v1</td>\n",
       "      <td>When \"Better\" Prompts Hurt: Evaluation-Driven ...</td>\n",
       "      <td>[Daniel Commey]</td>\n",
       "      <td>Evaluating Large Language Model (LLM) applicat...</td>\n",
       "      <td>2026-01-29 17:32:34+00:00</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>https://arxiv.org/pdf/2601.22025v1</td>\n",
       "      <td>Title: When \"Better\" Prompts Hurt: Evaluation-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2601.21969v1</td>\n",
       "      <td>Token-Guard: Towards Token-Level Hallucination...</td>\n",
       "      <td>[Yifan Zhu, Huiqiang Rong, Haoran Luo]</td>\n",
       "      <td>Large Language Models (LLMs) often hallucinate...</td>\n",
       "      <td>2026-01-29 16:48:47+00:00</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>https://arxiv.org/pdf/2601.21969v1</td>\n",
       "      <td>Title: Token-Guard: Towards Token-Level Halluc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2601.21937v1</td>\n",
       "      <td>Retrieval-Infused Reasoning Sandbox: A Benchma...</td>\n",
       "      <td>[Shuangshuang Ying, Zheyu Wang, Yunjian Peng, ...</td>\n",
       "      <td>Despite strong performance on existing benchma...</td>\n",
       "      <td>2026-01-29 16:26:19+00:00</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>https://arxiv.org/pdf/2601.21937v1</td>\n",
       "      <td>Title: Retrieval-Infused Reasoning Sandbox: A ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2601.21654v1</td>\n",
       "      <td>ScholarGym: Benchmarking Deep Research Workflo...</td>\n",
       "      <td>[Hao Shen, Hang Yang, Zhouhong Gu]</td>\n",
       "      <td>Tool-augmented large language models have adva...</td>\n",
       "      <td>2026-01-29 12:51:44+00:00</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>https://arxiv.org/pdf/2601.21654v1</td>\n",
       "      <td>Title: ScholarGym: Benchmarking Deep Research ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2601.21947v1</td>\n",
       "      <td>ToolWeaver: Weaving Collaborative Semantics fo...</td>\n",
       "      <td>[Bowen Fang, Wen Ye, Yunyue Su, Jinghao Zhang,...</td>\n",
       "      <td>Prevalent retrieval-based tool-use pipelines s...</td>\n",
       "      <td>2026-01-29 16:29:53+00:00</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>https://arxiv.org/pdf/2601.21947v1</td>\n",
       "      <td>Title: ToolWeaver: Weaving Collaborative Seman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2601.21714v1</td>\n",
       "      <td>E-mem: Multi-agent based Episodic Context Reco...</td>\n",
       "      <td>[Kaixiang Wang, Yidan Lin, Jiong Lou, Zhaojiac...</td>\n",
       "      <td>The evolution of Large Language Model (LLM) ag...</td>\n",
       "      <td>2026-01-29 13:42:42+00:00</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>https://arxiv.org/pdf/2601.21714v1</td>\n",
       "      <td>Title: E-mem: Multi-agent based Episodic Conte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>2601.21468v1</td>\n",
       "      <td>MemOCR: Layout-Aware Visual Memory for Efficie...</td>\n",
       "      <td>[Yaorui Shi, Shugui Liu, Yu Yang, Wenyu Mao, Y...</td>\n",
       "      <td>Long-horizon agentic reasoning necessitates ef...</td>\n",
       "      <td>2026-01-29 09:47:17+00:00</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>https://arxiv.org/pdf/2601.21468v1</td>\n",
       "      <td>Title: MemOCR: Layout-Aware Visual Memory for ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                              title  \\\n",
       "175  2601.21340v1  EHR-RAG: Bridging Long-Horizon Structured Elec...   \n",
       "51   2601.21916v1  JADE: Bridging the Strategic-Operational Gap i...   \n",
       "52   2601.21912v1  ProRAG: Process-Supervised Reinforcement Learn...   \n",
       "27   2601.22025v1  When \"Better\" Prompts Hurt: Evaluation-Driven ...   \n",
       "41   2601.21969v1  Token-Guard: Towards Token-Level Hallucination...   \n",
       "47   2601.21937v1  Retrieval-Infused Reasoning Sandbox: A Benchma...   \n",
       "101  2601.21654v1  ScholarGym: Benchmarking Deep Research Workflo...   \n",
       "45   2601.21947v1  ToolWeaver: Weaving Collaborative Semantics fo...   \n",
       "89   2601.21714v1  E-mem: Multi-agent based Episodic Context Reco...   \n",
       "144  2601.21468v1  MemOCR: Layout-Aware Visual Memory for Efficie...   \n",
       "\n",
       "                                               authors  \\\n",
       "175                   [Lang Cao, Qingyu Chen, Yue Guo]   \n",
       "51   [Yiqun Chen, Erhan Zhang, Tianyi Hu, Shijie Wa...   \n",
       "52             [Zhao Wang, Ziliang Zhao, Zhicheng Dou]   \n",
       "27                                     [Daniel Commey]   \n",
       "41              [Yifan Zhu, Huiqiang Rong, Haoran Luo]   \n",
       "47   [Shuangshuang Ying, Zheyu Wang, Yunjian Peng, ...   \n",
       "101                 [Hao Shen, Hang Yang, Zhouhong Gu]   \n",
       "45   [Bowen Fang, Wen Ye, Yunyue Su, Jinghao Zhang,...   \n",
       "89   [Kaixiang Wang, Yidan Lin, Jiong Lou, Zhaojiac...   \n",
       "144  [Yaorui Shi, Shugui Liu, Yu Yang, Wenyu Mao, Y...   \n",
       "\n",
       "                                              abstract  \\\n",
       "175  Electronic Health Records (EHRs) provide rich ...   \n",
       "51   The evolution of Retrieval-Augmented Generatio...   \n",
       "52   Reinforcement learning (RL) has become a promi...   \n",
       "27   Evaluating Large Language Model (LLM) applicat...   \n",
       "41   Large Language Models (LLMs) often hallucinate...   \n",
       "47   Despite strong performance on existing benchma...   \n",
       "101  Tool-augmented large language models have adva...   \n",
       "45   Prevalent retrieval-based tool-use pipelines s...   \n",
       "89   The evolution of Large Language Model (LLM) ag...   \n",
       "144  Long-horizon agentic reasoning necessitates ef...   \n",
       "\n",
       "                    published primary_category  \\\n",
       "175 2026-01-29 07:06:34+00:00            cs.AI   \n",
       "51  2026-01-29 16:06:44+00:00            cs.AI   \n",
       "52  2026-01-29 16:04:59+00:00            cs.AI   \n",
       "27  2026-01-29 17:32:34+00:00            cs.CL   \n",
       "41  2026-01-29 16:48:47+00:00            cs.CL   \n",
       "47  2026-01-29 16:26:19+00:00            cs.AI   \n",
       "101 2026-01-29 12:51:44+00:00            cs.AI   \n",
       "45  2026-01-29 16:29:53+00:00            cs.AI   \n",
       "89  2026-01-29 13:42:42+00:00            cs.AI   \n",
       "144 2026-01-29 09:47:17+00:00            cs.AI   \n",
       "\n",
       "                                    url  \\\n",
       "175  https://arxiv.org/pdf/2601.21340v1   \n",
       "51   https://arxiv.org/pdf/2601.21916v1   \n",
       "52   https://arxiv.org/pdf/2601.21912v1   \n",
       "27   https://arxiv.org/pdf/2601.22025v1   \n",
       "41   https://arxiv.org/pdf/2601.21969v1   \n",
       "47   https://arxiv.org/pdf/2601.21937v1   \n",
       "101  https://arxiv.org/pdf/2601.21654v1   \n",
       "45   https://arxiv.org/pdf/2601.21947v1   \n",
       "89   https://arxiv.org/pdf/2601.21714v1   \n",
       "144  https://arxiv.org/pdf/2601.21468v1   \n",
       "\n",
       "                                         combined_text  \n",
       "175  Title: EHR-RAG: Bridging Long-Horizon Structur...  \n",
       "51   Title: JADE: Bridging the Strategic-Operationa...  \n",
       "52   Title: ProRAG: Process-Supervised Reinforcemen...  \n",
       "27   Title: When \"Better\" Prompts Hurt: Evaluation-...  \n",
       "41   Title: Token-Guard: Towards Token-Level Halluc...  \n",
       "47   Title: Retrieval-Infused Reasoning Sandbox: A ...  \n",
       "101  Title: ScholarGym: Benchmarking Deep Research ...  \n",
       "45   Title: ToolWeaver: Weaving Collaborative Seman...  \n",
       "89   Title: E-mem: Multi-agent based Episodic Conte...  \n",
       "144  Title: MemOCR: Layout-Aware Visual Memory for ...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f9a11b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "[{'id': '2601.21340v1', 'title': 'EHR-RAG: Bridging Long-Horizon Structured Electronic Health Records and Large Language Models via Enhanced Retrieval-Augmented Generation', 'cleaned_authors': 'Lang Cao, Qingyu Chen, Yue Guo', 'abstract': 'Electronic Health Records (EHRs) provide rich longitudinal clinical evidence that is central to medical decision-making, motivating the use of retrieval-augmented generation (RAG) to ground large language model (LLM) predictions. However, long-horizon EHRs often exceed LLM context limits, and existing approaches commonly rely on truncation or vanilla retrieval strategies that discard clinically relevant events and temporal dependencies. To address these challenges, we propose EHR-RAG, a retrieval-augmented framework designed for accurate interpretation of long-horizon structured EHR data. EHR-RAG introduces three components tailored to longitudinal clinical prediction tasks: Event- and Time-Aware Hybrid EHR Retrieval to preserve clinical structure and temporal dynamics, Adaptive Iterative Retrieval to progressively refine queries in order to expand broad evidence coverage, and Dual-Path Evidence Retrieval and Reasoning to jointly retrieves and reasons over both factual and counterfactual evidence. Experiments across four long-horizon EHR prediction tasks show that EHR-RAG consistently outperforms the strongest LLM-based baselines, achieving an average Macro-F1 improvement of 10.76%. Overall, our work highlights the potential of retrieval-augmented LLMs to advance clinical prediction on structured EHR data in practice.'}, {'id': '2601.21916v1', 'title': 'JADE: Bridging the Strategic-Operational Gap in Dynamic Agentic RAG', 'cleaned_authors': 'Yiqun Chen, Erhan Zhang, Tianyi Hu, Shijie Wang, Zixuan Yang, Meizhi Zhong, Xiaochi Wei, Yan Gao, Yi Wu, Yao Hu, Jiaxin Mao', 'abstract': \"The evolution of Retrieval-Augmented Generation (RAG) has shifted from static retrieval pipelines to dynamic, agentic workflows where a central planner orchestrates multi-turn reasoning. However, existing paradigms face a critical dichotomy: they either optimize modules jointly within rigid, fixed-graph architectures, or empower dynamic planning while treating executors as frozen, black-box tools. We identify that this \\\\textit{decoupled optimization} creates a ``strategic-operational mismatch,'' where sophisticated planning strategies fail to materialize due to unadapted local executors, often leading to negative performance gains despite increased system complexity. In this paper, we propose \\\\textbf{JADE} (\\\\textbf{J}oint \\\\textbf{A}gentic \\\\textbf{D}ynamic \\\\textbf{E}xecution), a unified framework for the joint optimization of planning and execution within dynamic, multi-turn workflows. By modeling the system as a cooperative multi-agent team unified under a single shared backbone, JADE enables end-to-end learning driven by outcome-based rewards. This approach facilitates \\\\textit{co-adaptation}: the planner learns to operate within the capability boundaries of the executors, while the executors evolve to align with high-level strategic intent. Empirical results demonstrate that JADE transforms disjoint modules into a synergistic system, yielding remarkable performance improvements via joint optimization and enabling a flexible balance between efficiency and effectiveness through dynamic workflow orchestration.\"}, {'id': '2601.21912v1', 'title': 'ProRAG: Process-Supervised Reinforcement Learning for Retrieval-Augmented Generation', 'cleaned_authors': 'Zhao Wang, Ziliang Zhao, Zhicheng Dou', 'abstract': 'Reinforcement learning (RL) has become a promising paradigm for optimizing Retrieval-Augmented Generation (RAG) in complex reasoning tasks. However, traditional outcome-based RL approaches often suffer from reward sparsity and inefficient credit assignment, as coarse-grained scalar rewards fail to identify specific erroneous steps within long-horizon trajectories. This ambiguity frequently leads to \"process hallucinations\", where models reach correct answers through flawed logic or redundant retrieval steps. Although recent process-aware approaches attempt to mitigate this via static preference learning or heuristic reward shaping, they often lack the on-policy exploration capabilities required to decouple step-level credit from global outcomes. To address these challenges, we propose ProRAG, a process-supervised reinforcement learning framework designed to integrate learned step-level supervision into the online optimization loop. Our framework consists of four stages: (1) Supervised Policy Warmup to initialize the model with a structured reasoning format; (2) construction of an MCTS-based Process Reward Model (PRM) to quantify intermediate reasoning quality; (3) PRM-Guided Reasoning Refinement to align the policy with fine-grained process preferences; and (4) Process-Supervised Reinforcement Learning with a dual-granularity advantage mechanism. By aggregating step-level process rewards with global outcome signals, ProRAG provides precise feedback for every action. Extensive experiments on five multi-hop reasoning benchmarks demonstrate that ProRAG achieves superior overall performance compared to strong outcome-based and process-aware RL baselines, particularly on complex long-horizon tasks, validating the effectiveness of fine-grained process supervision. The code and model are available at https://github.com/lilinwz/ProRAG.'}, {'id': '2601.22025v1', 'title': 'When \"Better\" Prompts Hurt: Evaluation-Driven Iteration for LLM Applications', 'cleaned_authors': 'Daniel Commey', 'abstract': 'Evaluating Large Language Model (LLM) applications differs from traditional software testing because outputs are stochastic, high-dimensional, and sensitive to prompt and model changes. We present an evaluation-driven workflow - Define, Test, Diagnose, Fix - that turns these challenges into a repeatable engineering loop.   We introduce the Minimum Viable Evaluation Suite (MVES), a tiered set of recommended evaluation components for (i) general LLM applications, (ii) retrieval-augmented generation (RAG), and (iii) agentic tool-use workflows. We also synthesize common evaluation methods (automated checks, human rubrics, and LLM-as-judge) and discuss known judge failure modes.   In reproducible local experiments (Ollama; Llama 3 8B Instruct and Qwen 2.5 7B Instruct), we observe that a generic \"improved\" prompt template can trade off behaviors: on our small structured suites, extraction pass rate decreased from 100% to 90% and RAG compliance from 93.3% to 80% for Llama 3 when replacing task-specific prompts with generic rules, while instruction-following improved. These findings motivate evaluation-driven prompt iteration and careful claim calibration rather than universal prompt recipes.   All test suites, harnesses, and results are included for reproducibility.'}, {'id': '2601.21969v1', 'title': 'Token-Guard: Towards Token-Level Hallucination Control via Self-Checking Decoding', 'cleaned_authors': 'Yifan Zhu, Huiqiang Rong, Haoran Luo', 'abstract': 'Large Language Models (LLMs) often hallucinate, generating content inconsistent with the input. Retrieval-Augmented Generation (RAG) and Reinforcement Learning with Human Feedback (RLHF) can mitigate hallucinations but require resource-intensive retrieval or large-scale fine-tuning. Decoding-based methods are lighter yet lack explicit hallucination control. To address this, we present Token-Guard, a token-level hallucination control method based on self-checking decoding. Token-Guard performs internal verification at each reasoning step to detect hallucinated tokens before they propagate. Candidate fragments are further evaluated in a latent space with explicit hallucination risk scoring, while iterative pruning and regeneration dynamically correct detected errors. Experiments on HALU datasets show Token-Guard substantially reduces hallucinations and improves generation accuracy, offering a scalable, modular solution for reliable LLM outputs. Our code is publicly available.'}, {'id': '2601.21937v1', 'title': 'Retrieval-Infused Reasoning Sandbox: A Benchmark for Decoupling Retrieval and Reasoning Capabilities', 'cleaned_authors': 'Shuangshuang Ying, Zheyu Wang, Yunjian Peng, Jin Chen, Yuhao Wu, Hongbin Lin, Dingyu He, Siyi Liu, Gengchen Yu, YinZhu Piao ... YiXin Cao, Ge Zhang', 'abstract': 'Despite strong performance on existing benchmarks, it remains unclear whether large language models can reason over genuinely novel scientific information. Most evaluations score end-to-end RAG pipelines, where reasoning is confounded with retrieval and toolchain choices, and the signal is further contaminated by parametric memorization and open-web volatility. We introduce DeR2, a controlled deep-research sandbox that isolates document-grounded reasoning while preserving core difficulties of deep search: multi-step synthesis, denoising, and evidence-based conclusion making. DeR2 decouples evidence access from reasoning via four regimes--Instruction-only, Concepts (gold concepts without documents), Related-only (only relevant documents), and Full-set (relevant documents plus topically related distractors)--yielding interpretable regime gaps that operationalize retrieval loss vs. reasoning loss and enable fine-grained error attribution. To prevent parametric leakage, we apply a two-phase validation that requires parametric failure without evidence while ensuring oracle-concept solvability. To ensure reproducibility, each instance provides a frozen document library (drawn from 2023-2025 theoretical papers) with expert-annotated concepts and validated rationales. Experiments across a diverse set of state-of-the-art foundation models reveal substantial variation and significant headroom: some models exhibit mode-switch fragility, performing worse with the Full-set than with Instruction-only, while others show structural concept misuse, correctly naming concepts but failing to execute them as procedures.'}, {'id': '2601.21654v1', 'title': 'ScholarGym: Benchmarking Deep Research Workflows on Academic Literature Retrieval', 'cleaned_authors': 'Hao Shen, Hang Yang, Zhouhong Gu', 'abstract': 'Tool-augmented large language models have advanced from single-turn question answering to deep research workflows that iteratively plan queries, invoke external tools, and synthesize information to address complex information needs. Evaluating such workflows presents a fundamental challenge: reliance on live APIs introduces non-determinism, as tool invocations may yield different results across runs due to temporal drift, rate limiting, and evolving backend states. This variance undermines reproducibility and invalidates cross-system comparisons.   We present ScholarGym, a simulation environment for reproducible evaluation of deep research workflows on academic literature. The environment decouples workflow components into query planning, tool invocation, and relevance assessment, enabling fine-grained analysis of each stage under controlled conditions. Built on a static corpus of 570K papers with deterministic retrieval, ScholarGym provides 2,536 queries with expert-annotated ground truth. Experiments across diverse backbone models reveal how reasoning capabilities, planning strategies, and selection mechanisms interact over iterative refinement.'}, {'id': '2601.21947v1', 'title': 'ToolWeaver: Weaving Collaborative Semantics for Scalable Tool Use in Large Language Models', 'cleaned_authors': 'Bowen Fang, Wen Ye, Yunyue Su, Jinghao Zhang, Qiang Liu, Yesheng Liu, Xin Sun, Shu Wu, Jiabing Yang, Baole Wei, Liang Wang', 'abstract': \"Prevalent retrieval-based tool-use pipelines struggle with a dual semantic challenge: their retrievers often employ encoders that fail to capture complex semantics, while the Large Language Model (LLM) itself lacks intrinsic tool knowledge from its natural language pretraining. Generative methods offer a powerful alternative by unifying selection and execution, tasking the LLM to directly learn and generate tool identifiers. However, the common practice of mapping each tool to a unique new token introduces substantial limitations: it creates a scalability and generalization crisis, as the vocabulary size explodes and each tool is assigned a semantically isolated token. This approach also creates a semantic bottleneck that hinders the learning of collaborative tool relationships, as the model must infer them from sparse co-occurrences of monolithic tool IDs within a vast library. To address these limitations, we propose ToolWeaver, a novel generative tool learning framework that encodes tools into hierarchical sequences. This approach makes vocabulary expansion logarithmic to the number of tools. Crucially, it enables the model to learn collaborative patterns from the dense co-occurrence of shared codes, rather than the sparse co-occurrence of monolithic tool IDs. We generate these structured codes through a novel tokenization process designed to weave together a tool's intrinsic semantics with its extrinsic co-usage patterns. These structured codes are then integrated into the LLM through a generative alignment stage, where the model is fine-tuned to produce the hierarchical code sequences. Evaluation results with nearly 47,000 tools show that ToolWeaver significantly outperforms state-of-the-art methods, establishing a more scalable, generalizable, and semantically-aware foundation for advanced tool-augmented agents.\"}, {'id': '2601.21714v1', 'title': 'E-mem: Multi-agent based Episodic Context Reconstruction for LLM Agent Memory', 'cleaned_authors': 'Kaixiang Wang, Yidan Lin, Jiong Lou, Zhaojiacheng Zhou, Bunyod Suvonov, Jie Li', 'abstract': 'The evolution of Large Language Model (LLM) agents towards System~2 reasoning, characterized by deliberative, high-precision problem-solving, requires maintaining rigorous logical integrity over extended horizons. However, prevalent memory preprocessing paradigms suffer from destructive de-contextualization. By compressing complex sequential dependencies into pre-defined structures (e.g., embeddings or graphs), these methods sever the contextual integrity essential for deep reasoning. To address this, we propose E-mem, a framework shifting from Memory Preprocessing to Episodic Context Reconstruction. Inspired by biological engrams, E-mem employs a heterogeneous hierarchical architecture where multiple assistant agents maintain uncompressed memory contexts, while a central master agent orchestrates global planning. Unlike passive retrieval, our mechanism empowers assistants to locally reason within activated segments, extracting context-aware evidence before aggregation. Evaluations on the LoCoMo benchmark demonstrate that E-mem achieves over 54\\\\% F1, surpassing the state-of-the-art GAM by 7.75\\\\%, while reducing token cost by over 70\\\\%.'}, {'id': '2601.21468v1', 'title': 'MemOCR: Layout-Aware Visual Memory for Efficient Long-Horizon Reasoning', 'cleaned_authors': 'Yaorui Shi, Shugui Liu, Yu Yang, Wenyu Mao, Yuxin Chen, Qi GU, Hui Su, Xunliang Cai, Xiang Wang, An Zhang', 'abstract': 'Long-horizon agentic reasoning necessitates effectively compressing growing interaction histories into a limited context window. Most existing memory systems serialize history as text, where token-level cost is uniform and scales linearly with length, often spending scarce budget on low-value details. To this end, we introduce MemOCR, a multimodal memory agent that improves long-horizon reasoning under tight context budgets by allocating memory space with adaptive information density through visual layout. Concretely, MemOCR maintains a structured rich-text memory (e.g., headings, highlights) and renders it into an image that the agent consults for memory access, visually prioritizing crucial evidence while aggressively compressing auxiliary details. To ensure robustness across varying memory budgets, we train MemOCR with reinforcement learning under budget-aware objectives that expose the agent to diverse compression levels. Across long-context multi-hop and single-hop question-answering benchmarks, MemOCR outperforms strong text-based baselines and achieves more effective context utilization under extreme budgets.'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m refined_df = \u001b[43mfine_rank_with_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtop_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 69\u001b[39m, in \u001b[36mfine_rank_with_llm\u001b[39m\u001b[34m(top_papers_df, user_interest)\u001b[39m\n\u001b[32m     67\u001b[39m refined_results = []\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m paper_analysis \u001b[38;5;129;01min\u001b[39;00m llm_output:\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     paper_id = \u001b[43mpaper_analysis\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mid\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     70\u001b[39m     matching_paper = top_papers_df[top_papers_df[\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m] == paper_id].iloc[\u001b[32m0\u001b[39m]\n\u001b[32m     72\u001b[39m     refined_results.append({\n\u001b[32m     73\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m: paper_id,\n\u001b[32m     74\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33murl\u001b[39m\u001b[33m\"\u001b[39m: matching_paper[\u001b[33m'\u001b[39m\u001b[33murl\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     78\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mreasoning\u001b[39m\u001b[33m\"\u001b[39m: paper_analysis.get(\u001b[33m'\u001b[39m\u001b[33mwhy\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     79\u001b[39m     })\n",
      "\u001b[31mTypeError\u001b[39m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "refined_df = fine_rank_with_llm(top_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2b56cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>abstract</th>\n",
       "      <th>published</th>\n",
       "      <th>primary_category</th>\n",
       "      <th>url</th>\n",
       "      <th>combined_text</th>\n",
       "      <th>relevance_score</th>\n",
       "      <th>novelty_score</th>\n",
       "      <th>soundness_score</th>\n",
       "      <th>why</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2601.21340v1</td>\n",
       "      <td>EHR-RAG: Bridging Long-Horizon Structured Elec...</td>\n",
       "      <td>[Lang Cao, Qingyu Chen, Yue Guo]</td>\n",
       "      <td>Electronic Health Records (EHRs) provide rich ...</td>\n",
       "      <td>2026-01-29 07:06:34+00:00</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>https://arxiv.org/pdf/2601.21340v1</td>\n",
       "      <td>Title: EHR-RAG: Bridging Long-Horizon Structur...</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>This paper proposes a novel framework for retr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2601.21937v1</td>\n",
       "      <td>Retrieval-Infused Reasoning Sandbox: A Benchma...</td>\n",
       "      <td>[Shuangshuang Ying, Zheyu Wang, Yunjian Peng, ...</td>\n",
       "      <td>Despite strong performance on existing benchma...</td>\n",
       "      <td>2026-01-29 16:26:19+00:00</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>https://arxiv.org/pdf/2601.21937v1</td>\n",
       "      <td>Title: Retrieval-Infused Reasoning Sandbox: A ...</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>This paper proposes a novel benchmark for eval...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2601.21916v1</td>\n",
       "      <td>JADE: Bridging the Strategic-Operational Gap i...</td>\n",
       "      <td>[Yiqun Chen, Erhan Zhang, Tianyi Hu, Shijie Wa...</td>\n",
       "      <td>The evolution of Retrieval-Augmented Generatio...</td>\n",
       "      <td>2026-01-29 16:06:44+00:00</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>https://arxiv.org/pdf/2601.21916v1</td>\n",
       "      <td>Title: JADE: Bridging the Strategic-Operationa...</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>This paper proposes a novel framework for join...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2601.21912v1</td>\n",
       "      <td>ProRAG: Process-Supervised Reinforcement Learn...</td>\n",
       "      <td>[Zhao Wang, Ziliang Zhao, Zhicheng Dou]</td>\n",
       "      <td>Reinforcement learning (RL) has become a promi...</td>\n",
       "      <td>2026-01-29 16:04:59+00:00</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>https://arxiv.org/pdf/2601.21912v1</td>\n",
       "      <td>Title: ProRAG: Process-Supervised Reinforcemen...</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>This paper proposes a novel process-supervised...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2601.21654v1</td>\n",
       "      <td>ScholarGym: Benchmarking Deep Research Workflo...</td>\n",
       "      <td>[Hao Shen, Hang Yang, Zhouhong Gu]</td>\n",
       "      <td>Tool-augmented large language models have adva...</td>\n",
       "      <td>2026-01-29 12:51:44+00:00</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>https://arxiv.org/pdf/2601.21654v1</td>\n",
       "      <td>Title: ScholarGym: Benchmarking Deep Research ...</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>This paper proposes a novel simulation environ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2601.21947v1</td>\n",
       "      <td>ToolWeaver: Weaving Collaborative Semantics fo...</td>\n",
       "      <td>[Bowen Fang, Wen Ye, Yunyue Su, Jinghao Zhang,...</td>\n",
       "      <td>Prevalent retrieval-based tool-use pipelines s...</td>\n",
       "      <td>2026-01-29 16:29:53+00:00</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>https://arxiv.org/pdf/2601.21947v1</td>\n",
       "      <td>Title: ToolWeaver: Weaving Collaborative Seman...</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>This paper proposes a novel generative tool le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2601.21714v1</td>\n",
       "      <td>E-mem: Multi-agent based Episodic Context Reco...</td>\n",
       "      <td>[Kaixiang Wang, Yidan Lin, Jiong Lou, Zhaojiac...</td>\n",
       "      <td>The evolution of Large Language Model (LLM) ag...</td>\n",
       "      <td>2026-01-29 13:42:42+00:00</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>https://arxiv.org/pdf/2601.21714v1</td>\n",
       "      <td>Title: E-mem: Multi-agent based Episodic Conte...</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>This paper proposes a novel framework for epis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2601.21468v1</td>\n",
       "      <td>MemOCR: Layout-Aware Visual Memory for Efficie...</td>\n",
       "      <td>[Yaorui Shi, Shugui Liu, Yu Yang, Wenyu Mao, Y...</td>\n",
       "      <td>Long-horizon agentic reasoning necessitates ef...</td>\n",
       "      <td>2026-01-29 09:47:17+00:00</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>https://arxiv.org/pdf/2601.21468v1</td>\n",
       "      <td>Title: MemOCR: Layout-Aware Visual Memory for ...</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>This paper proposes a novel multimodal memory ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2601.21969v1</td>\n",
       "      <td>Token-Guard: Towards Token-Level Hallucination...</td>\n",
       "      <td>[Yifan Zhu, Huiqiang Rong, Haoran Luo]</td>\n",
       "      <td>Large Language Models (LLMs) often hallucinate...</td>\n",
       "      <td>2026-01-29 16:48:47+00:00</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>https://arxiv.org/pdf/2601.21969v1</td>\n",
       "      <td>Title: Token-Guard: Towards Token-Level Halluc...</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>This paper proposes a novel approach to contro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2601.22025v1</td>\n",
       "      <td>When \"Better\" Prompts Hurt: Evaluation-Driven ...</td>\n",
       "      <td>[Daniel Commey]</td>\n",
       "      <td>Evaluating Large Language Model (LLM) applicat...</td>\n",
       "      <td>2026-01-29 17:32:34+00:00</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>https://arxiv.org/pdf/2601.22025v1</td>\n",
       "      <td>Title: When \"Better\" Prompts Hurt: Evaluation-...</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>This paper proposes a novel evaluation workflo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                              title  \\\n",
       "0  2601.21340v1  EHR-RAG: Bridging Long-Horizon Structured Elec...   \n",
       "5  2601.21937v1  Retrieval-Infused Reasoning Sandbox: A Benchma...   \n",
       "1  2601.21916v1  JADE: Bridging the Strategic-Operational Gap i...   \n",
       "2  2601.21912v1  ProRAG: Process-Supervised Reinforcement Learn...   \n",
       "6  2601.21654v1  ScholarGym: Benchmarking Deep Research Workflo...   \n",
       "7  2601.21947v1  ToolWeaver: Weaving Collaborative Semantics fo...   \n",
       "8  2601.21714v1  E-mem: Multi-agent based Episodic Context Reco...   \n",
       "9  2601.21468v1  MemOCR: Layout-Aware Visual Memory for Efficie...   \n",
       "4  2601.21969v1  Token-Guard: Towards Token-Level Hallucination...   \n",
       "3  2601.22025v1  When \"Better\" Prompts Hurt: Evaluation-Driven ...   \n",
       "\n",
       "                                             authors  \\\n",
       "0                   [Lang Cao, Qingyu Chen, Yue Guo]   \n",
       "5  [Shuangshuang Ying, Zheyu Wang, Yunjian Peng, ...   \n",
       "1  [Yiqun Chen, Erhan Zhang, Tianyi Hu, Shijie Wa...   \n",
       "2            [Zhao Wang, Ziliang Zhao, Zhicheng Dou]   \n",
       "6                 [Hao Shen, Hang Yang, Zhouhong Gu]   \n",
       "7  [Bowen Fang, Wen Ye, Yunyue Su, Jinghao Zhang,...   \n",
       "8  [Kaixiang Wang, Yidan Lin, Jiong Lou, Zhaojiac...   \n",
       "9  [Yaorui Shi, Shugui Liu, Yu Yang, Wenyu Mao, Y...   \n",
       "4             [Yifan Zhu, Huiqiang Rong, Haoran Luo]   \n",
       "3                                    [Daniel Commey]   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Electronic Health Records (EHRs) provide rich ...   \n",
       "5  Despite strong performance on existing benchma...   \n",
       "1  The evolution of Retrieval-Augmented Generatio...   \n",
       "2  Reinforcement learning (RL) has become a promi...   \n",
       "6  Tool-augmented large language models have adva...   \n",
       "7  Prevalent retrieval-based tool-use pipelines s...   \n",
       "8  The evolution of Large Language Model (LLM) ag...   \n",
       "9  Long-horizon agentic reasoning necessitates ef...   \n",
       "4  Large Language Models (LLMs) often hallucinate...   \n",
       "3  Evaluating Large Language Model (LLM) applicat...   \n",
       "\n",
       "                  published primary_category  \\\n",
       "0 2026-01-29 07:06:34+00:00            cs.AI   \n",
       "5 2026-01-29 16:26:19+00:00            cs.AI   \n",
       "1 2026-01-29 16:06:44+00:00            cs.AI   \n",
       "2 2026-01-29 16:04:59+00:00            cs.AI   \n",
       "6 2026-01-29 12:51:44+00:00            cs.AI   \n",
       "7 2026-01-29 16:29:53+00:00            cs.AI   \n",
       "8 2026-01-29 13:42:42+00:00            cs.AI   \n",
       "9 2026-01-29 09:47:17+00:00            cs.AI   \n",
       "4 2026-01-29 16:48:47+00:00            cs.CL   \n",
       "3 2026-01-29 17:32:34+00:00            cs.CL   \n",
       "\n",
       "                                  url  \\\n",
       "0  https://arxiv.org/pdf/2601.21340v1   \n",
       "5  https://arxiv.org/pdf/2601.21937v1   \n",
       "1  https://arxiv.org/pdf/2601.21916v1   \n",
       "2  https://arxiv.org/pdf/2601.21912v1   \n",
       "6  https://arxiv.org/pdf/2601.21654v1   \n",
       "7  https://arxiv.org/pdf/2601.21947v1   \n",
       "8  https://arxiv.org/pdf/2601.21714v1   \n",
       "9  https://arxiv.org/pdf/2601.21468v1   \n",
       "4  https://arxiv.org/pdf/2601.21969v1   \n",
       "3  https://arxiv.org/pdf/2601.22025v1   \n",
       "\n",
       "                                       combined_text  relevance_score  \\\n",
       "0  Title: EHR-RAG: Bridging Long-Horizon Structur...                8   \n",
       "5  Title: Retrieval-Infused Reasoning Sandbox: A ...                8   \n",
       "1  Title: JADE: Bridging the Strategic-Operationa...                8   \n",
       "2  Title: ProRAG: Process-Supervised Reinforcemen...                8   \n",
       "6  Title: ScholarGym: Benchmarking Deep Research ...                8   \n",
       "7  Title: ToolWeaver: Weaving Collaborative Seman...                8   \n",
       "8  Title: E-mem: Multi-agent based Episodic Conte...                8   \n",
       "9  Title: MemOCR: Layout-Aware Visual Memory for ...                8   \n",
       "4  Title: Token-Guard: Towards Token-Level Halluc...                8   \n",
       "3  Title: When \"Better\" Prompts Hurt: Evaluation-...                8   \n",
       "\n",
       "   novelty_score  soundness_score  \\\n",
       "0              9                9   \n",
       "5              9                9   \n",
       "1              9                7   \n",
       "2              9                7   \n",
       "6              9                7   \n",
       "7              9                7   \n",
       "8              9                7   \n",
       "9              9                7   \n",
       "4              7                9   \n",
       "3              6                9   \n",
       "\n",
       "                                                 why  \n",
       "0  This paper proposes a novel framework for retr...  \n",
       "5  This paper proposes a novel benchmark for eval...  \n",
       "1  This paper proposes a novel framework for join...  \n",
       "2  This paper proposes a novel process-supervised...  \n",
       "6  This paper proposes a novel simulation environ...  \n",
       "7  This paper proposes a novel generative tool le...  \n",
       "8  This paper proposes a novel framework for epis...  \n",
       "9  This paper proposes a novel multimodal memory ...  \n",
       "4  This paper proposes a novel approach to contro...  \n",
       "3  This paper proposes a novel evaluation workflo...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refined_df.sort_values(by=['relevance_score', 'novelty_score', 'soundness_score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7979ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m\n",
      "ollama.generate(\n",
      "    model: str = \u001b[33m''\u001b[39m,\n",
      "    prompt: Optional[str] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    suffix: Optional[str] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    *,\n",
      "    system: Optional[str] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    template: Optional[str] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    context: Optional[Sequence[int]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    stream: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    think: Optional[bool] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    logprobs: Optional[bool] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    top_logprobs: Optional[int] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    raw: Optional[bool] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    format: Union[Literal[\u001b[33m''\u001b[39m, \u001b[33m'json'\u001b[39m], dict[str, Any], NoneType] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    images: Optional[Sequence[Union[str, bytes, ollama._types.Image]]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    options: Union[Mapping[str, Any], ollama._types.Options, NoneType] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    keep_alive: Union[float, str, NoneType] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      ") -> Union[ollama._types.GenerateResponse, collections.abc.Iterator[ollama._types.GenerateResponse]]\n",
      "\u001b[31mDocstring:\u001b[39m\n",
      "Create a response using the requested model.\n",
      "\n",
      "Raises `RequestError` if a model is not provided.\n",
      "\n",
      "Raises `ResponseError` if the request could not be fulfilled.\n",
      "\n",
      "Returns `GenerateResponse` if `stream` is `False`, otherwise returns a `GenerateResponse` generator.\n",
      "\u001b[31mFile:\u001b[39m      ~/Desktop/open_source/arxiv_recommender/.venv/lib/python3.13/site-packages/ollama/_client.py\n",
      "\u001b[31mType:\u001b[39m      method"
     ]
    }
   ],
   "source": [
    "ollama.generate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39201f16",
   "metadata": {},
   "outputs": [],
   "source": [
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arxiv-recommender",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

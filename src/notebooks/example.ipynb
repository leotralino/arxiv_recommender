{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import logging\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# do logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'b'.join(['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_recent_papers(categories=[\"cs.AI\"], days=1, max_results=100):\n",
    "    \"\"\"\n",
    "    Fetches papers from specific categories within a time window.\n",
    "    \"\"\"\n",
    "    # 1. Build Query (e.g., \"cat:cs.LG OR cat:cs.AI\")\n",
    "    query = \" OR \".join([f\"cat:{c}\" for c in categories])\n",
    "    \n",
    "    client = arxiv.Client(\n",
    "        page_size=100,\n",
    "        delay_seconds=3.0, # Be nice to ArXiv servers\n",
    "        num_retries=3\n",
    "    )\n",
    "    \n",
    "    search = arxiv.Search(\n",
    "        query=query,\n",
    "        max_results=max_results,\n",
    "        sort_by=arxiv.SortCriterion.SubmittedDate\n",
    "    )\n",
    "    \n",
    "    # 2. Time Window\n",
    "    threshold = datetime.datetime.now(datetime.timezone.utc) - datetime.timedelta(days=days)\n",
    "    \n",
    "    results = []\n",
    "    for result in client.results(search):\n",
    "        # ArXiv results are sorted by date, so we can break early\n",
    "        if result.published < threshold:\n",
    "            break\n",
    "            \n",
    "        results.append({\n",
    "            \"id\": result.entry_id.split('/')[-1],\n",
    "            \"title\": result.title,\n",
    "            \"authors\": [a.name for a in result.authors],\n",
    "            \"abstract\": result.summary.replace(\"\\n\", \" \"),\n",
    "            \"published\": result.published,\n",
    "            \"primary_category\": result.primary_category,\n",
    "            \"url\": result.pdf_url,\n",
    "        })\n",
    "        \n",
    "    since_time = threshold.strftime('%Y-%m-%d %H:%M')\n",
    "    print(\n",
    "        f\"Fetched {len(results)} new papers since {since_time}\"\n",
    "    )\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fetch_recent_papers(max_results=1000)\n",
    "df['combined_text'] = \"Title: \" + df['title'] + \" Abstract: \" + df['abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_interest_embedding = model.encode(\"I am interested in Retrieval-augmented generation (RAG).\")\n",
    "content_embedding = model.encode(df['combined_text'].tolist())\n",
    "\n",
    "print(np.shape(content_embedding))\n",
    "\n",
    "cosine_sim = np.dot(content_embedding, my_interest_embedding) / (np.linalg.norm(content_embedding, axis=1) * np.linalg.norm(my_interest_embedding))\n",
    "top_k_indices = np.argsort(-cosine_sim)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_df = df.iloc[top_k_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import json\n",
    "\n",
    "def get_authors(author_list):\n",
    "    \"\"\"\n",
    "    Formats the author list for LLM input, truncating if too long.\n",
    "    \"\"\"\n",
    "    # Assuming 'authors' is your list of strings\n",
    "    num_authors = len(author_list)\n",
    "\n",
    "    if num_authors <= 12:\n",
    "        # If list is small, just give them all\n",
    "        author_string = \", \".join(author_list)\n",
    "    else:\n",
    "        # Grab first 10 and last 2 (senior/corresponding positions)\n",
    "        first_part = author_list[:10]\n",
    "        last_part = author_list[-2:]\n",
    "        author_string = f\"{', '.join(first_part)} ... {', '.join(last_part)}\"\n",
    "    \n",
    "    return author_string\n",
    "\n",
    "def fine_rank_with_llm(top_papers_df, user_interest=\"RAG\"):\n",
    "    \"\"\"\n",
    "    Uses a local LLM to give a qualitative 'Quality Score' to the top candidates.\n",
    "    \"\"\"\n",
    "    top_papers_df = top_papers_df.copy()\n",
    "    top_papers_df['cleaned_authors'] = top_papers_df['authors'].apply(get_authors)\n",
    "    all_papers_json = top_papers_df[['id', 'title', 'cleaned_authors', 'abstract']].to_dict(orient='records')\n",
    "\n",
    "    print(len(all_papers_json))    \n",
    "    print(all_papers_json)\n",
    "\n",
    "    llm_ranking_prompt = f\"\"\"\n",
    "    ## Task\n",
    "\n",
    "    You are an expert AI and Physics PhD Researcher. \n",
    "    Given a list of papers with their titles, authors, and abstracts, you should help me decide which research papers to read based on my specific interest.\n",
    "    These papers are posted on arXiv today.\n",
    "    Your output should be top-5 results, stored in JSON format.\n",
    "\n",
    "    To select best papers, you should consider relevancy to my interest, novelty, and soundness of methodology. Use the author list to gauge credibility if needed.\n",
    "    \n",
    "\n",
    "    ## My Interest\n",
    "    My research interest topics: \"{user_interest}\"\n",
    "\n",
    "    \n",
    "    ## Input paper as JSON array\n",
    "    {all_papers_json}\n",
    "\n",
    "    ## Output\n",
    "\n",
    "    Provide a JSON response with:\n",
    "    - \"id\": The ArXiv ID of the paper.\n",
    "    - \"reasoning\": A one-sentence explanation of why this paper is worth reading or not.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = ollama.generate(\n",
    "        model='llama3:8b', \n",
    "        prompt=llm_ranking_prompt,\n",
    "        format='json', # Ensures we get a parsable dict back\n",
    "        options={'temperature': 0} # Keep it deterministic\n",
    "    )\n",
    "    \n",
    "    llm_output = json.loads(response['response'])\n",
    "\n",
    "    refined_results = []\n",
    "    for paper_analysis in llm_output:\n",
    "        paper_id = paper_analysis['id']\n",
    "        matching_paper = top_papers_df[top_papers_df['id'] == paper_id].iloc[0]\n",
    "        \n",
    "        refined_results.append({\n",
    "            \"id\": paper_id,\n",
    "            \"url\": matching_paper['url'],\n",
    "            \"title\": matching_paper['title'],\n",
    "            \"authors\": matching_paper['cleaned_authors'],\n",
    "            \"abstract\": matching_paper['abstract'],\n",
    "            \"reasoning\": paper_analysis.get('why', '')\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(refined_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_df = fine_rank_with_llm(top_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_df.sort_values(by=['relevance_score', 'novelty_score', 'soundness_score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama.generate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arxiv-recommender",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
